[{"path":"/articles/S1_probability.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning objectives","title":"S1_probability: Definitions and exercises","text":"understand use sample() understand use set.seed() control behavior random number generation distinguish sample size experiment replication size simulation Explain relationship precision probability estimate sample size associated experiment binomially distributed outcomes outcomes governed Poisson Negative Binomial models general Understand simulate data null (e.g., fair deck) alternative (e.g., biased deck) conditions Understand difference finite, countably infinite, uncountably infinite sample spaces Define use probability density functions cumulative distribution functions continuous outcomes joint probability distribution two random quantities contours bivariate density: empirical model-based covariance correlation","code":""},{"path":"/articles/S1_probability.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"S1_probability: Definitions and exercises","text":"concept probability “long run relative frequency”. ’ll work several models random events make concrete.","code":""},{"path":[]},{"path":[]},{"path":"/articles/S1_probability.html","id":"random-permutations-with-sample","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards","what":"Random permutations with sample()","title":"S1_probability: Definitions and exercises","text":"’ll take granted sample(x, size=length(x), replace=FALSE) R achieves goal “shuffling” elements x. Thus assume , x vector R, aspect ordering elements s1 can used predict anything ordering elements s2. words, sample(x, size, replace=FALSE) taken primitive operation permutes elements x “random” way.","code":"s1 = sample(x, size=length(x), replace=FALSE) s2 = sample(x, size=length(x), replace=FALSE) set.seed(5432) # initialize, for reproducibility, the random number generator sample(1:5, replace=FALSE) # permute (1,2,3,4,5) ## [1] 4 2 1 3 5 sample(1:5, replace=FALSE) # a new, unpredictable, permutation ## [1] 3 4 1 2 5"},{"path":"/articles/S1_probability.html","id":"exercises","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards > Random permutations with sample()","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"1: second permutation produced termed “unpredictable”? 2: Predict outcome sample(1:5, replace=FALSE), run just one shown .","code":""},{"path":"/articles/S1_probability.html","id":"card-deck-definitions-and-operations","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards","what":"Card deck definitions and operations","title":"S1_probability: Definitions and exercises","text":"card deck vector 52 elements. Unicode characters encode “suits”. already installed CSHstats (long time ago) use get access software needed computations document. fair deck one card combination “face” “suit”.","code":"BiocManager::install(\"vjcitn/CSHstats\")  # install.packages(\"BiocManager\") if necessary library(CSHstats) d = build_deck() d ##  [1] \"2 ♡\"  \"3 ♡\"  \"4 ♡\"  \"5 ♡\"  \"6 ♡\"  \"7 ♡\"  \"8 ♡\"  \"9 ♡\"  \"10 ♡\" \"J ♡\"  ## [11] \"Q ♡\"  \"K ♡\"  \"A ♡\"  \"2 ♢\"  \"3 ♢\"  \"4 ♢\"  \"5 ♢\"  \"6 ♢\"  \"7 ♢\"  \"8 ♢\"  ## [21] \"9 ♢\"  \"10 ♢\" \"J ♢\"  \"Q ♢\"  \"K ♢\"  \"A ♢\"  \"2 ♣\"  \"3 ♣\"  \"4 ♣\"  \"5 ♣\"  ## [31] \"6 ♣\"  \"7 ♣\"  \"8 ♣\"  \"9 ♣\"  \"10 ♣\" \"J ♣\"  \"Q ♣\"  \"K ♣\"  \"A ♣\"  \"2 ♤\"  ## [41] \"3 ♤\"  \"4 ♤\"  \"5 ♤\"  \"6 ♤\"  \"7 ♤\"  \"8 ♤\"  \"9 ♤\"  \"10 ♤\" \"J ♤\"  \"Q ♤\"  ## [51] \"K ♤\"  \"A ♤\" unique(suits(d)) ## [1] \"♡\" \"♢\" \"♣\" \"♤\" unique(faces(d)) ##  [1] \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"J\"  \"Q\"  \"K\"  \"A\" table(suits(d), faces(d)) ##     ##     10 2 3 4 5 6 7 8 9 A J K Q ##   ♡  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♢  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♣  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♤  1 1 1 1 1 1 1 1 1 1 1 1 1"},{"path":"/articles/S1_probability.html","id":"exercises-1","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards > Card deck definitions and operations","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"3: Write code produces new deck fair except two copies ten hearts. Verify new deck property.","code":""},{"path":"/articles/S1_probability.html","id":"shuffling-the-deck","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards","what":"Shuffling the deck","title":"S1_probability: Definitions and exercises","text":"reproducible shuffling event can programmed follows:","code":"set.seed(1234)  # any numeric seed will do but you need to record it shuffle_deck = function(d) sample(d, size=length(d), replace=FALSE) head(d)         # top 6 cards ## [1] \"2 ♡\" \"3 ♡\" \"4 ♡\" \"5 ♡\" \"6 ♡\" \"7 ♡\" head(shuffle_deck(d)) ## [1] \"3 ♣\"  \"4 ♢\"  \"10 ♢\" \"Q ♣\"  \"6 ♤\"  \"9 ♤\""},{"path":"/articles/S1_probability.html","id":"the-top-card-after-a-shuffle","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards","what":"The top card after a shuffle","title":"S1_probability: Definitions and exercises","text":"","code":"set.seed(4141) top_draw = function(d) shuffle_deck(d)[1] top_draw(d) ## [1] \"A ♤\" top_draw(d) ## [1] \"5 ♤\""},{"path":"/articles/S1_probability.html","id":"exercises-2","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Simulating shuffled playing cards > The top card after a shuffle","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"4: top card next shuffle? 5: Write code get third card. 6: probability top draw shuffled fair deck heart?","code":""},{"path":[]},{"path":"/articles/S1_probability.html","id":"a-simulation-process-repeated-shuffles-and-draws","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Estimating the probability of an event","what":"A simulation process: repeated shuffles and draws","title":"S1_probability: Definitions and exercises","text":"’s simple way estimating probability top draw shuffled fair deck heart, construed long run frequency. ’ll simulate 100 shuffles save results testing suit top card. concise approach R :","code":"heart_sign = function() \"\\U2661\"  # unicode U2661, prepend backslash heart_sign() ## [1] \"♡\" res = rep(NA, 100) for (i in 1:100) {  res[i] = (suits(top_draw(d)) == heart_sign()) # TRUE if top card is a heart } head(res) ## [1] FALSE FALSE  TRUE  TRUE  TRUE FALSE ### relative frequency of the event \"suit of top card is 'heart'\" sum(res)/length(res) ## [1] 0.36 mean(replicate( 100, suits(top_draw(d)) == heart_sign()) ) ## [1] 0.22"},{"path":"/articles/S1_probability.html","id":"exercises-3","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Estimating the probability of an event > A simulation process: repeated shuffles and draws","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"7: interpret difference two probability estimates given ?","code":""},{"path":"/articles/S1_probability.html","id":"replicating-the-estimation-process","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Estimating the probability of an event","what":"Replicating the estimation process","title":"S1_probability: Definitions and exercises","text":"Let’s intensify investigation aim understanding uncertainty estimation. ’ll define variable gives size “experiment”: shuffling 100 times ’ll refer sample size, SSIZE study estimation procedure replicating experiment N_REPLICATION times.","code":"SSIZE = 100 N_REPLICATION = 500 set.seed(10101) # initialize, for reproducibility, the random number generator doubsim = replicate(N_REPLICATION,      mean(replicate( SSIZE, suits(top_draw(d)) == heart_sign()) )     ) hist(doubsim, xlim=c(0,1))"},{"path":"/articles/S1_probability.html","id":"exercises-4","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Estimating the probability of an event > Replicating the estimation process","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"8: can make estimate probability event “suit top card ‘heart’” precise? Answer: increase SSIZE.  increased “sample size”, reduced variation experiment--experiment estimates probability heart suit top card.","code":"SSIZE = 500 set.seed(101012) doubsim2 = replicate(N_REPLICATION,      mean(replicate( SSIZE, suits(top_draw(d)) == heart_sign()) )     ) hist(doubsim2, xlim=c(0,1))"},{"path":"/articles/S1_probability.html","id":"formal-probability-models","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event","what":"Formal probability models","title":"S1_probability: Definitions and exercises","text":"Intuitively, probability drawing heart well-shuffled fair deck 1/4. repeat shuffling drawing one hundred times, expect around 25 draws reveal heart. Formal probability models enable us reason systematically mean around description expectation. models can also create accurate predictions likely outcomes complex events. useful define sample space probability model, set possible outcomes random process modeled. top-card-drawn example, sample space set suits, disregard face value. fair deck, point sample space probability \\(1/4\\). Events interest “top card heart” “top card heart”. probabilities events derivable probabilities constituent outcomes.","code":""},{"path":"/articles/S1_probability.html","id":"using-the-binomial-probability-model","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Formal probability models","what":"Using the binomial probability model","title":"S1_probability: Definitions and exercises","text":"series independent dichotomous events (true false, zero one, heart non-heart) can modeled using probability mass function binomial distribution. two parameters, \\(p\\) \\(n\\), \\(p\\) (unobservable) probability event (say “suit top card ‘heart’”) \\(n\\) number independent trials random dichotomy observed. \\(n\\) “trials”, event probability \\(p\\), probability seeing event \\(x\\) times \\[ Pr(X = x; n, p) = {\\binom{n}{x}} p^x(1-p)^{n-x} \\] written \\(X\\) denote random quantity \\(x\\) denote realization. single draw, \\(X\\) count hearts seen draw, \\[ Pr(X=0; 1, 1/4) = 1-1/4 = 3/4 \\] \\[ Pr(X=1; 1, 1/4) = 1/4 \\]","code":""},{"path":"/articles/S1_probability.html","id":"exercises-5","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Formal probability models > Using the binomial probability model","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"9: Modify production doubsim2 \\(x\\)-axis histogram units “number times top card heart”.","code":"hist(doubsim3, xlim=c(.15*500,.35*500), xlab=\"count of draws with heart as suit of top card\")"},{"path":"/articles/S1_probability.html","id":"visualizing-the-model-and-the-data","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Formal probability models","what":"Visualizing the model and the data","title":"S1_probability: Definitions and exercises","text":"formula given tells us frequently observe given count. R function dbinom can compute probability, multiply number realizations get height histogram.  Notice histogram, virtue binning counts, seem reflect shape theoretical frequency function given dots. can remedied increasing number replicates used. considerable research regarding design histogram displays. See ?nclass.Sturges references. One unpleasant feature display doubsim2 seems imply asymmetric distribution. Another way “cuts ” extremes.","code":"hist(doubsim3, xlim=c(.15*500,.35*500),     xlab=\"count of draws with heart as suit of top card\", ylim=c(0,115)) points(80:160, 2500*dbinom(80:160, 500, 13/52), pch=19, cex=.5) legend(78, 110, pch=19, legend=\"scaled dbinom(x, 500, .25)\", bty=\"n\", cex=.85)"},{"path":"/articles/S1_probability.html","id":"exercises-6","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > Formal probability models > Visualizing the model and the data","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"10: Write couple sentences carefully distinguishing displays doubsim2 doubsim3 . Explain choice heuristic name “doubsim”.","code":""},{"path":"/articles/S1_probability.html","id":"a-biased-deck","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event","what":"A biased deck","title":"S1_probability: Definitions and exercises","text":"Recall layout fair deck: make copy one card remove one:","code":"table(suits(d), faces(d)) ##     ##     10 2 3 4 5 6 7 8 9 A J K Q ##   ♡  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♢  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♣  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♤  1 1 1 1 1 1 1 1 1 1 1 1 1 bd = d bd[18] = bd[3] table(suits(bd), faces(bd)) ##     ##     10 2 3 4 5 6 7 8 9 A J K Q ##   ♡  1 1 1 2 1 1 1 1 1 1 1 1 1 ##   ♢  1 1 1 1 1 0 1 1 1 1 1 1 1 ##   ♣  1 1 1 1 1 1 1 1 1 1 1 1 1 ##   ♤  1 1 1 1 1 1 1 1 1 1 1 1 1"},{"path":"/articles/S1_probability.html","id":"exercises-7","dir":"Articles","previous_headings":"The probability of a 0-1 (binary or dichotomous) event > A biased deck","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"11: probability top card drawn shuffle bd heart? 12: probability top card drawn shuffle bd club?","code":""},{"path":"/articles/S1_probability.html","id":"probability-models-for-categorical-outcomes","dir":"Articles","previous_headings":"","what":"Probability models for categorical outcomes","title":"S1_probability: Definitions and exercises","text":"Thus far focused dichotomy: top draw heart . can consider possible suits 4-valued response.","code":""},{"path":"/articles/S1_probability.html","id":"a-contingency-table","dir":"Articles","previous_headings":"Probability models for categorical outcomes","what":"A contingency table","title":"S1_probability: Definitions and exercises","text":"Let’s simulate process drawing top card shuffling, tabulate suits observed.","code":"set.seed(4321) table( tops <- replicate(500, suits(top_draw(bd))) ) ##  ##   ♡   ♢   ♣   ♤  ## 148 106 126 120"},{"path":"/articles/S1_probability.html","id":"exercises-8","dir":"Articles","previous_headings":"Probability models for categorical outcomes > A contingency table","what":"Exercises","title":"S1_probability: Definitions and exercises","text":"13: expect counts suits table deck fair?","code":""},{"path":"/articles/S1_probability.html","id":"multinomial-model-and-simulation","dir":"Articles","previous_headings":"Probability models for categorical outcomes","what":"Multinomial model and simulation","title":"S1_probability: Definitions and exercises","text":"adopted binomial model number top draws suit “heart” fixed number shuffles: \\[ Pr(X = x; n, p) = {\\binom{n}{x}} p^x(1-p)^{n-x} \\] fair deck, \\(p= 1/4\\). generalization vector responses multinomial model. can use (ordered) vector counts top draws yielding different suits. problem parameters \\(N\\) (number trials), \\(k\\) (number categories), \\(p_1, \\ldots, p_k\\), category-specific probabilities. realizations denoted \\(x_1, \\ldots, x_k\\) \\(\\sum_i x_i = N\\). Now probability model defined terms random vectors vectors probabilities: \\[ Pr(X_1 = x_1, \\ldots, X_k = x_k) = \\frac{n!}{x_1! \\cdots x_k!} p_1^{x_1} \\cdots p_k^{x_k} \\] provides elegant way producing frequency distributions suit top draw. introduce pseudorandom number generation multinomial model, using rmultinom. Notice use deck d producing matrix counts. Previously applied sample() 52-vector cards. Now use model develop data interest.","code":"NREP = 10000 SSIZE = 500 mnmat = rmultinom(NREP, SSIZE, rep(.25,4)) rownames(mnmat) = c(\"\\U2661\", \"\\U2662\", \"\\U2663\", \"\\U2664\") mnmat[,1]  # one draw ##   ♡   ♢   ♣   ♤  ## 131 125 110 134 apply(mnmat,1,mean) ##        ♡        ♢        ♣        ♤  ## 124.9621 124.9080 125.0362 125.0937"},{"path":"/articles/S1_probability.html","id":"exercise","dir":"Articles","previous_headings":"Probability models for categorical outcomes > Multinomial model and simulation","what":"Exercise","title":"S1_probability: Definitions and exercises","text":"14: Modify call rmultinom obtain distributions top card suits biased deck bd. Hint: Change part call involving rep().","code":""},{"path":[]},{"path":"/articles/S1_probability.html","id":"modeling-collections-of-counts","dir":"Articles","previous_headings":"Probability models for categorical outcomes > The Poisson distribution","what":"Modeling collections of counts","title":"S1_probability: Definitions and exercises","text":"Outcomes taking form integer counts arise many appications. example, quarry floor divided squares one meter side. 30 squares searched fossil number specimens per square recorded. square 5 specimens. (Example Probability Models Applications, . Olkin, L. Gleser, C. Derman, ch 6.3.) table includes nspec, number specimens square, freq, number squares corresponding number specimens, pred, predicted number specimens based Poisson model mean parameter 0.73 specimens per square. derive quantities pred, used dpois counts per square, mean parameter set 0.73. derive , use obtain average number fossils per square. Poisson model mean \\(\\lambda\\) \\[ Pr(X = x; \\lambda) = \\frac{e^{-\\lambda}\\lambda^k}{k!} \\]","code":"foss = data.frame(nspec=0:4, freq=c(16,9,3,1,1), pred=round(30*dpois(0:4, 0.73), 2)) foss ##   nspec freq  pred ## 1     0   16 14.46 ## 2     1    9 10.55 ## 3     2    3  3.85 ## 4     3    1  0.94 ## 5     4    1  0.17 sum(foss$nspec * foss$freq)/30 ## [1] 0.7333333"},{"path":"/articles/S1_probability.html","id":"exercise-1","dir":"Articles","previous_headings":"Probability models for categorical outcomes > The Poisson distribution","what":"Exercise","title":"S1_probability: Definitions and exercises","text":"15: Use formula explain prediction 14.46 squares zero fossils.","code":""},{"path":"/articles/S1_probability.html","id":"a-countably-infinite-sample-space","dir":"Articles","previous_headings":"Probability models for categorical outcomes > The Poisson distribution","what":"A countably infinite sample space","title":"S1_probability: Definitions and exercises","text":"binomial multinomial models discussed finite discrete sample spaces. sample space Poisson model set non-negative integers. mass function arises fact \\(e^\\lambda = \\sum \\lambda^k/k!\\), sum taken non-negative integers.","code":""},{"path":"/articles/S1_probability.html","id":"the-negative-binomial-model","dir":"Articles","previous_headings":"Probability models for categorical outcomes","what":"The negative binomial model","title":"S1_probability: Definitions and exercises","text":"mass function \\[ p(x; \\theta, \\mu) = \\frac{\\Gamma(\\theta + x)}{\\Gamma(\\theta)y!}     \\frac{\\mu^y \\theta^\\theta}{(\\mu + \\theta)^{\\theta + y}} \\] useful later material.","code":""},{"path":"/articles/S1_probability.html","id":"mean-variance","dir":"Articles","previous_headings":"Probability models for categorical outcomes","what":"Mean, variance","title":"S1_probability: Definitions and exercises","text":"sample mean vector \\(x = (x_1, \\ldots, x_n)\\) defined \\(\\bar{x} = n^{-1}\\sum_i x_i\\). (unbiased estimator ) sample variance \\((n-1)^{-1}\\sum_i (x_i - \\bar{x})^2\\). sometimes refer mean variance context probability models rather samples. mean continuous distribution defined discrete distribution probability mass function \\(p\\) mean \\[ E(x) = \\sum x p(x), \\] sum taken sample space associated model. Writing \\(\\mu\\) mean value distribution study, variance discrete distribution \\[ V(x) = \\sum (x-\\mu)^2 p(x) dx. \\]","code":""},{"path":"/articles/S1_probability.html","id":"models-for-continuous-outcomes","dir":"Articles","previous_headings":"","what":"Models for continuous outcomes","title":"S1_probability: Definitions and exercises","text":"models ’ve considered thus far discrete responses – sample space either finite countably infinite. continuous responses, sample space uncountably infinite. sample space may interval real line, whole real line. discuss define probabilities subsets sample space.","code":""},{"path":"/articles/S1_probability.html","id":"univariate-response","dir":"Articles","previous_headings":"Models for continuous outcomes","what":"Univariate response","title":"S1_probability: Definitions and exercises","text":"concreteness, use RNA-seq data derived Cancer Genome Atlas. ’ll focus 79 values normalized RSEM-based estimates expression YY1 adrenocortical carcinoma. refer vector “real valued” outcomes.","code":"data(yy1_ex) head(yy1_ex) ## TCGA-OR-A5J1-01A-11R-A29S-07 TCGA-OR-A5J2-01A-11R-A29S-07  ##                    1455.8117                    1688.6318  ## TCGA-OR-A5J3-01A-11R-A29S-07 TCGA-OR-A5J5-01A-11R-A29S-07  ##                    1821.3598                    1877.6143  ## TCGA-OR-A5J6-01A-31R-A29S-07 TCGA-OR-A5J7-01A-11R-A29S-07  ##                     634.3023                    1132.3706"},{"path":"/articles/S1_probability.html","id":"cumulative-distribution-function-quantiles","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response","what":"Cumulative distribution function; quantiles","title":"S1_probability: Definitions and exercises","text":"’ll use capital letters denote random variables. formal definition “random variable” given textbooks; use term informally refer quantities regard random. function \\(F(x) = \\mbox{Pr}(X < x)\\) called cumulative distribution function (CDF) random variable \\(X\\). YY1 measures, can produce visualization associated CDF:  quantiles distribution given inverse CDF. quantile function takes number \\(p\\) 0 1 returns number \\(F^{-1}(p)\\). graph shows 0.80 quantile distribution YY1 vector 1584.","code":"plot(ecdf(yy1_ex)) abline(h=.8, lty=2) arrows(1583, .8, 1583, 0, lty=2)"},{"path":"/articles/S1_probability.html","id":"exercise-2","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response","what":"Exercise","title":"S1_probability: Definitions and exercises","text":"16: Show proportion YY1 observations exceeding 1584 approximately 20%.","code":""},{"path":"/articles/S1_probability.html","id":"histogram-probability-density-function","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response","what":"Histogram, probability density function","title":"S1_probability: Definitions and exercises","text":"histogram tunable display relative frequencies values vector.  probability density function continuous random variable \\(X\\) satisfies \\[ \\int_a^b f(x) dx = \\mbox{Pr}(< X < b) \\] can estimate density function sample various ways. simple illustration:  interest use approxfun numerical integration density estimate given , estimate probability YY1 expression lies given interval. acceptable? changing bandwidth density estimator produce better results? potential overfitting problem?","code":"par(mfrow=c(2,1), mar=c(4,3,1,1)) hist(yy1_ex, xlim=c(400, 2600)) hist(yy1_ex, breaks=20, xlim=c(400, 2600)) plot(dd <- density(yy1_ex)) dfun = approxfun(dd$x, dd$y) integrate(dfun, 1000, 1500)  # density-based ## 0.4821651 with absolute error < 1e-05 mean(yy1_ex >=1000 & yy1_ex <= 1500) # empirical ## [1] 0.5316456"},{"path":"/articles/S1_probability.html","id":"some-widely-used-models-for-continuous-responses","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response","what":"Some widely used models for continuous responses","title":"S1_probability: Definitions and exercises","text":"’ll use simulation illustrate shapes various distributions. R makes simple family functions whose names begin r.","code":""},{"path":"/articles/S1_probability.html","id":"uniform-distribution-on-01","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response > Some widely used models for continuous responses","what":"Uniform distribution on [0,1]","title":"S1_probability: Definitions and exercises","text":"density function \\(f(x) = 1\\) \\(x \\[0,1]\\) 0 otherwise.","code":"hist(runif(10000, 0, 1), prob=TRUE)"},{"path":"/articles/S1_probability.html","id":"exercise-3","dir":"Articles","previous_headings":"","what":"S1_probability: Definitions and exercises","title":"S1_probability: Definitions and exercises","text":"17: Use code like obtain value density random variable uniform density interval [0, 2].","code":""},{"path":"/articles/S1_probability.html","id":"gaussian-model","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response > Some widely used models for continuous responses","what":"Gaussian model","title":"S1_probability: Definitions and exercises","text":"Gaussian distribution also called “normal”. shape position real line determined mean variance. Symbolically, model often written \\(N(\\mu, \\sigma^2)\\), density function \\(f(x) = 1/\\sqrt{2\\pi \\sigma^2} \\exp\\{(x-\\mu)^2/2 \\sigma^2\\}\\).","code":"hist(rnorm(10000, 0, 1), prob=TRUE) lines(seq(-4,4,len=100), dnorm(seq(-4,4,len=100)))"},{"path":"/articles/S1_probability.html","id":"exponential-and-gamma-models-for-survival-data","dir":"Articles","previous_headings":"Models for continuous outcomes > Univariate response > Some widely used models for continuous responses","what":"Exponential and Gamma models for survival data","title":"S1_probability: Definitions and exercises","text":"exponential model (confused exponential family models) defined random variables positive values. example survival times. ’ll use dataset survival package illustrate.  density function exponential model \\(f(x) = \\lambda e ^ {-\\lambda x}\\). formulation, \\(\\lambda\\) referred rate parameter. mean distribution \\(1/\\lambda\\).","code":"library(survival) # use myeloma records from Mayo clinic, remove censored times md = myeloma$futime[myeloma$death==1 & myeloma$entry == 0] hist(md, breaks=20, prob=TRUE, ylim=c(0,.001)) mean(md) ## [1] 1044.768 ss = seq(0,8000,.1) lines(ss, dexp(ss, rate=1/mean(md)))"},{"path":"/articles/S1_probability.html","id":"exercise-4","dir":"Articles","previous_headings":"","what":"S1_probability: Definitions and exercises","title":"S1_probability: Definitions and exercises","text":"18: close median exponential model rate 1/1045 sample median myeloma survival times? relate interpretation plot ?","code":""},{"path":"/articles/S1_probability.html","id":"mean-and-variance-for-continuous-models","dir":"Articles","previous_headings":"Models for continuous outcomes","what":"Mean and variance for continuous models","title":"S1_probability: Definitions and exercises","text":"continuous distributions, mean value \\[ E(x) = \\int x f(x) dx. \\] Writing \\(\\mu\\) mean value distribution study, variance continuous distribution \\[ V(x) = \\int (x-\\mu)^2 f(x) dx. \\]","code":""},{"path":"/articles/S1_probability.html","id":"multivariate-response","dir":"Articles","previous_headings":"Models for continuous outcomes","what":"Multivariate response","title":"S1_probability: Definitions and exercises","text":"’ve seen use univariate probability models many facets. concept joint distribution multiple random quantities central reasoning interactions among components complicated processes. following example, obtained normalized expression measures EGR1 FOS adrenocortical carcinoma tumors studied TCGA. ’ll use built-bivariate density estimation show relationship expression two transcription factors ACC.","code":"data(fos_ex) data(egr1_ex) bivdf = data.frame(fos_ex, egr1_ex) library(ggplot2) ggplot(bivdf, aes(x=log(fos_ex), y=log(egr1_ex))) + geom_point() + geom_density_2d()"},{"path":"/articles/S1_probability.html","id":"joint-cumulative-distribution-function","dir":"Articles","previous_headings":"Models for continuous outcomes > Multivariate response","what":"Joint cumulative distribution function","title":"S1_probability: Definitions and exercises","text":"’ll focus case continuous bivariate response denoted \\((X,Y)\\). joint cumulative distribution function (cdf) \\[ F(x,y) = Pr(X < x, Y < y) \\] , log FOS log EGR1, can evaluate \\(F(7,7)\\) follows: call empirical estimate \\(F(7,7)\\).","code":"mean(log(fos_ex)<7 & log(egr1_ex)<7) ## [1] 0.278481"},{"path":"/articles/S1_probability.html","id":"covariance-matrix-bivariate-case","dir":"Articles","previous_headings":"Models for continuous outcomes > Multivariate response","what":"Covariance matrix, bivariate case","title":"S1_probability: Definitions and exercises","text":"covariance two random variables \\(Cov(X,Y) = EXY - (EX)(EY)\\); covariance matrix symmetric, variances diagonal, covariance diagonal.","code":"var(log(fos_ex)) # univariate ## [1] 1.194019 covmat = var(cbind(log(fos_ex), log(egr1_ex))) # matrix covmat ##           [,1]      [,2] ## [1,] 1.1940188 0.9746936 ## [2,] 0.9746936 1.4137188"},{"path":"/articles/S1_probability.html","id":"using-the-bivariate-normal-model","dir":"Articles","previous_headings":"Models for continuous outcomes > Multivariate response","what":"Using the bivariate normal model","title":"S1_probability: Definitions and exercises","text":"Given estimates bivariate mean covariance, can use multivariate normal cumulative density function produce contours distribution elliptical shapes, opposed wiggly contours saw .  estimate \\(F(7,7)\\) using model ’ll call model-based estimate \\(F(7,7)\\).","code":"bmean = c(mean(log(fos_ex)), mean(log(egr1_ex))) library(mvtnorm) xgrid = seq(3,10,.05) ygrid = seq(3,10,.05) ngrid = length(xgrid) nd = matrix(NA, ngrid, ngrid) for (i in 1:ngrid) {  # inefficient!  for (j in 1:ngrid) {   nd[i,j] = dmvnorm(c(xgrid[i],ygrid[j]), bmean, covmat)   }  } contour(xgrid, ygrid, nd, ylab=\"log EGR1\", xlab=\"log FOS\") points(log(fos_ex), log(egr1_ex), col=\"gray\", pch=19) pmvnorm(upper=c(7,7), mean=bmean, sigma=covmat) ## [1] 0.3368775 ## attr(,\"error\") ## [1] 1e-15 ## attr(,\"msg\") ## [1] \"Normal Completion\""},{"path":"/articles/S1_probability.html","id":"exercise-5","dir":"Articles","previous_headings":"Models for continuous outcomes > Multivariate response > Using the bivariate normal model","what":"Exercise","title":"S1_probability: Definitions and exercises","text":"19: Obtain empirical model-based estimates \\(F(6,5)\\) (log FOS, log EGR1).","code":""},{"path":"/articles/S1_probability.html","id":"probabilistic-independence-and-dependence","dir":"Articles","previous_headings":"Models for continuous outcomes > Multivariate response","what":"Probabilistic independence and dependence","title":"S1_probability: Definitions and exercises","text":"“tilted contour ellipses” shown just indicate knowledge value log FOS tells us variation values log EGR1. log FOS 6, value log EGR1 much likely around 6 around 9. use concept conditional distribution address concept, denote conditional distribution function \\(F(x|y)\\), vertical bar denoting conditioning. Specifically, \\(F(x|Y=y)\\) = Pr(\\(X<x\\)) given \\(Y = y\\). Probabilistic independence two random quantities can formulated condition \\(F(x|y) = F(x)\\): knowledge value \\(Y\\) provides information distribution \\(X\\).","code":""},{"path":"/articles/S1_probability.html","id":"measures-of-correlation","dir":"Articles","previous_headings":"Models for continuous outcomes > Multivariate response","what":"Measures of correlation","title":"S1_probability: Definitions and exercises","text":"correlation coefficient two random quantities ratio covariance square root product variances. 20: Use elements covmat computed produce estimate correlation log FOS log EGR1, compare cor() R (log FOS, log EGR1).","code":""},{"path":"/articles/S2_EDA.html","id":"eda-exploratory-data-analysis","dir":"Articles","previous_headings":"","what":"EDA: Exploratory data analysis","title":"S2_EDA: Exploratory data analysis and visualization","text":"field EDA changed, thanks advances computational visualization technology. Classical EDA addressed Assessing distributional shape Comparing batches numbers: Boxplots beyond Transformations; handling “outliers” recently, can consider exploratory data activities use interactive tables interactive graphics purpose-built graphical user interfaces explore concerns. principles include high volumes involved, sampling dimension reduction relevant every facet data accessible exploration summarization","code":""},{"path":"/articles/S2_EDA.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning objectives","title":"S2_EDA: Exploratory data analysis and visualization","text":"simple statistics may fail disclose structure visualization always conducted understand might use shiny explore tunable data visualization Box-Cox transformation family provides clues choosing transformation look qqnorm, qqplot allows general comparisons Shiny + TnT allow exploration data context linear genome annotation","code":""},{"path":"/articles/S2_EDA.html","id":"anscombes-quartet-statistics-that-miss-the-point","dir":"Articles","previous_headings":"","what":"Anscombe’s quartet: statistics that miss the point","title":"S2_EDA: Exploratory data analysis and visualization","text":"1973 Francis Anscombe constructed four bivariate datasets. four datasets interest pairs columns (x1, y1), (x2, y2), …. discussion probability provided definitions mean, variance, covariance, correlation. quick check means variables quartet. use apply function general arguments X array-like entity, MARGIN defines dimension along FUN computed additional arguments possibly provided .... MARGIN 1, FUN computed “row”, MARGIN 2, FUN computed “column”. also introduce helper function rounded_stat rounds result univariate statistic. code demonstrates x y variables identical means standard deviations. Nevertheless, variables plotted one another, :","code":"library(DT) datatable(anscombe) apply(X, MARGIN, FUN, ..., simplify=TRUE) rounded_stat = function(x, stat=mean, ndig=2) round(stat(x), ndig) apply(anscombe, 2, rounded_stat, stat=mean) ##  x1  x2  x3  x4  y1  y2  y3  y4  ## 9.0 9.0 9.0 9.0 7.5 7.5 7.5 7.5 apply(anscombe, 2, rounded_stat, stat=sd) ##   x1   x2   x3   x4   y1   y2   y3   y4  ## 3.32 3.32 3.32 3.32 2.03 2.03 2.03 2.03"},{"path":"/articles/S2_EDA.html","id":"exercises","dir":"Articles","previous_headings":"Anscombe’s quartet: statistics that miss the point","what":"Exercises","title":"S2_EDA: Exploratory data analysis and visualization","text":"1. Show four correlation coefficients (x1, y1), …, (x4, y4) identical (rounding). 2. blog post addresses tidyverse approach handling data. Read blog post try get comfortable various steps towards producing using “tidy” representation.","code":"# use BiocManager::install(\"tidyverse\") if necessary library(tidyverse) tidy_anscombe <- anscombe %>%  pivot_longer(cols = everything(),               names_to = c(\".value\", \"set\"),               names_pattern = \"(.)(.)\") library(ggplot2) ggplot(tidy_anscombe,        aes(x = x,            y = y)) +   geom_point() +    facet_wrap(~set) +   geom_smooth(method = \"lm\", se = FALSE) ## `geom_smooth()` using formula 'y ~ x'"},{"path":[]},{"path":"/articles/S2_EDA.html","id":"univariate","dir":"Articles","previous_headings":"Exploring distributional shape","what":"Univariate","title":"S2_EDA: Exploratory data analysis and visualization","text":"mode distribution “common value”. peak histogram correspond mode corresponding distribution discrete random variable. continuous random variables, mode given peak density function. basic question univariate dataset : multimodal distribution? Live Exercise: programming interactive exploration. Use R studio’s File control produce new “Shiny app”, give name “modality”. use “Run app” control. slider controls number bins used summarize values times geyser eruption. many modes might underlying distribution ?","code":""},{"path":"/articles/S2_EDA.html","id":"transformation","dir":"Articles","previous_headings":"Exploring distributional shape","what":"Transformation","title":"S2_EDA: Exploratory data analysis and visualization","text":"search transformation best symmetrizes skewed distribution, boxcox function MASS library can used. origins procedure reported Royal Statistical Society 1964. JRSS paper basic idea can construct series functional transformations random variable produce distribution (transformed scale) approximately normal. Box-Cox family transformations indexed single parameter, \\(\\lambda\\). transformation variable \\(y\\) \\(y^*(\\lambda) = \\lambda^{-1}(y^\\lambda-1)\\) (\\(\\lambda \\neq 0\\)) log \\(y\\) \\(\\lambda = 0\\) provides smooth traversal (fractional) power, logarithm, reciprocal power operations \\(y\\). \\(\\lambda\\) 1, transformation indicated.  boxcox function MASS library trace likelihood function maximized distribution \\(y^*(\\lambda)\\) close Gaussian possible.","code":"opar = par(no.readonly=TRUE) par(mfrow=c(2,2), mar=c(3,2,1,1)) data(fos_ex) hist(fos_ex, main=\"raw\") hist(sqrt(fos_ex), main=\"sqrt\") hist(fos_ex^2, main=\"square\") hist(log(fos_ex), main=\"log\") par(opar) library(MASS) boxcox(fos_ex~1) # must use formula"},{"path":"/articles/S2_EDA.html","id":"exercise","dir":"Articles","previous_headings":"Exploring distributional shape > Transformation","what":"Exercise","title":"S2_EDA: Exploratory data analysis and visualization","text":"3. transformation boxcox() recommend applied log(egr1_ex)? 4. transformation boxcox() recommend applied geyser data started ?","code":""},{"path":"/articles/S2_EDA.html","id":"is-it-gaussian","dir":"Articles","previous_headings":"Exploring distributional shape","what":"Is it Gaussian?","title":"S2_EDA: Exploratory data analysis and visualization","text":"concept Q-Q plot (quantile-quantile plot) used compare given data vector reference distribution (distribution data vector).  configuration points Q-Q plot form straight line, reference distribution probably appropriate.","code":"qqnorm(fos_ex, main=\"Compare FOS to Gaussian distribution\")"},{"path":"/articles/S2_EDA.html","id":"exercises-1","dir":"Articles","previous_headings":"Exploring distributional shape > Is it Gaussian?","what":"Exercises","title":"S2_EDA: Exploratory data analysis and visualization","text":"5. Use qqnorm log(fos_ex) comment. 6. zsc = function(x) (x - mean(x))/sd(x). special qqnorm(zsc(log(fos_ex)))?","code":""},{"path":"/articles/S2_EDA.html","id":"bivariate","dir":"Articles","previous_headings":"Exploring distributional shape","what":"Bivariate","title":"S2_EDA: Exploratory data analysis and visualization","text":"can use density estimation plane reason multimodality bivariate data. example(geom_density_2d):","code":"library(datasets) data(faithful) m <- ggplot(faithful, aes(x = eruptions, y = waiting)) +   geom_point() + xlim(0.5, 6) + ylim(40, 110) # contour lines m + geom_density_2d()"},{"path":"/articles/S2_EDA.html","id":"exercise-1","dir":"Articles","previous_headings":"Exploring distributional shape > Bivariate","what":"Exercise","title":"S2_EDA: Exploratory data analysis and visualization","text":"7. Comment meaning “local modes” “marginal” displays.","code":"opar = par(no.readonly=TRUE) par(mfrow=c(1,2), mar=c(3,2,1,1)) plot(density(faithful$erup, .08)) plot(density(faithful$wait, 1.4)) par(opar)"},{"path":"/articles/S2_EDA.html","id":"exercise-2","dir":"Articles","previous_headings":"Exploring distributional shape > Bivariate","what":"Exercise","title":"S2_EDA: Exploratory data analysis and visualization","text":"8. (advanced): Produce shiny app controller bandwidth density estimator viewing bivariate structure faithful data. ```","code":""},{"path":"/articles/S2_EDA.html","id":"visualizing-data-in-the-context-of-the-genome","dir":"Articles","previous_headings":"","what":"Visualizing data in the context of the genome","title":"S2_EDA: Exploratory data analysis and visualization","text":"use https://vjcitn.shinyapps.io/tnt4dn8 look GWAS eQTL data jointly.","code":""},{"path":[]},{"path":"/articles/S3_hypothesis_testing.html","id":"the-fairness-hypothesis","dir":"Articles","previous_headings":"Inference","what":"The fairness hypothesis","title":"S3_inference: Definitions and exercises","text":"Let \\(C_1\\) denote suit top card revealed fair shuffle. can state hypothesis fairness deck repeated draws top card shuffling \\[ H_0: Pr(C_1 = \\heartsuit) = Pr(C_1 = \\diamondsuit) = Pr(C_1 = \\clubsuit) = Pr(C_1 = \\spadesuit) = 1/4 \\] frequentist framework statistical inference, define procedures testing (null) hypotheses specified error probabilities. Type error occurs null hypothesis true test results assertion false. Traditionally try keep probability Type errors 5%. Type II error occurs null hypothesis false test result assertion false. Traditionally try keep probability Type II errors 20%.","code":""},{"path":"/articles/S3_hypothesis_testing.html","id":"exercises","dir":"Articles","previous_headings":"Inference > The fairness hypothesis","what":"Exercises","title":"S3_inference: Definitions and exercises","text":"14: Propose test \\(H_0\\) given . Assume results top card draws 100 shuffles. 15: Consider approach testing \\(H_0\\) basis top card draws \\(N\\) shuffles:","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vince Carey. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Carey V (2022). CSHstats: discussions exercises classical statistics CSHL 2022. R package version 0.0.12, https://github.com/vjcitn/CSHstats.","code":"@Manual{,   title = {CSHstats: discussions and exercises on classical statistics for CSHL 2022},   author = {Vince Carey},   year = {2022},   note = {R package version 0.0.12},   url = {https://github.com/vjcitn/CSHstats}, }"},{"path":"/index.html","id":"cshstats","dir":"","previous_headings":"","what":"discussions and exercises on classical statistics for CSHL 2022","title":"discussions and exercises on classical statistics for CSHL 2022","text":"R vignettes/pkgdown elementary statistics summer course DRAFT! preliminary 19 May 2022 One view conceptual scheme course three main vertices:  students start lower left vertex need move along bottom edge work high-dimensional data generated sequencing technologies. Ultimately want use data climb edges expand biological medical knowledge. ’ll conduct introductory exploration four topic areas statistics data science: Probability simulation Exploratory data analysis visualization Hypothesis testing Linear models","code":""},{"path":"/reference/accex.html","id":null,"dir":"Reference","previous_headings":"","what":"MultiAssayExperiment instance for ACC — accex","title":"MultiAssayExperiment instance for ACC — accex","text":"MultiAssayExperiment instance ACC","code":""},{"path":"/reference/accex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MultiAssayExperiment instance for ACC — accex","text":"","code":"accex"},{"path":"/reference/accex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"MultiAssayExperiment instance for ACC — accex","text":"MultiAssayExperiment","code":""},{"path":"/reference/build_deck.html","id":null,"dir":"Reference","previous_headings":"","what":"make a deck of cards with 52 elements and unicode symbols for suits — build_deck","title":"make a deck of cards with 52 elements and unicode symbols for suits — build_deck","text":"make deck cards 52 elements unicode symbols suits","code":""},{"path":"/reference/build_deck.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make a deck of cards with 52 elements and unicode symbols for suits — build_deck","text":"","code":"build_deck()"},{"path":"/reference/c50.html","id":null,"dir":"Reference","previous_headings":"","what":"meaningless integers — c50","title":"meaningless integers — c50","text":"meaningless integers","code":""},{"path":"/reference/c50.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"meaningless integers — c50","text":"","code":"c50"},{"path":"/reference/c50.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"meaningless integers — c50","text":"numeric vector","code":""},{"path":"/reference/c5000.html","id":null,"dir":"Reference","previous_headings":"","what":"read depth for 5000 positions on pasilla chr4, from example(coverage) for GenomicAlignments — c5000","title":"read depth for 5000 positions on pasilla chr4, from example(coverage) for GenomicAlignments — c5000","text":"read depth 5000 positions pasilla chr4, example(coverage) GenomicAlignments","code":""},{"path":"/reference/c5000.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read depth for 5000 positions on pasilla chr4, from example(coverage) for GenomicAlignments — c5000","text":"","code":"c5000"},{"path":"/reference/c5000.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"read depth for 5000 positions on pasilla chr4, from example(coverage) for GenomicAlignments — c5000","text":"numeric vector","code":""},{"path":"/reference/doubsim.html","id":null,"dir":"Reference","previous_headings":"","what":"simulated draws of top card from a shuffled deck of cards — doubsim","title":"simulated draws of top card from a shuffled deck of cards — doubsim","text":"simulated draws top card shuffled deck cards","code":""},{"path":"/reference/doubsim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulated draws of top card from a shuffled deck of cards — doubsim","text":"","code":"doubsim"},{"path":"/reference/doubsim.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"simulated draws of top card from a shuffled deck of cards — doubsim","text":"character vector","code":""},{"path":"/reference/doubsim2.html","id":null,"dir":"Reference","previous_headings":"","what":"simulated draws of top card from a shuffled  deck of cards — doubsim2","title":"simulated draws of top card from a shuffled  deck of cards — doubsim2","text":"simulated draws top card shuffled  deck cards","code":""},{"path":"/reference/doubsim2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulated draws of top card from a shuffled  deck of cards — doubsim2","text":"","code":"doubsim2"},{"path":"/reference/doubsim2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"simulated draws of top card from a shuffled  deck of cards — doubsim2","text":"character vector","code":""},{"path":"/reference/doubsim3.html","id":null,"dir":"Reference","previous_headings":"","what":"simulated draws of top card from a shuffled  deck of cards — doubsim3","title":"simulated draws of top card from a shuffled  deck of cards — doubsim3","text":"simulated draws top card shuffled  deck cards","code":""},{"path":"/reference/doubsim3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulated draws of top card from a shuffled  deck of cards — doubsim3","text":"","code":"doubsim3"},{"path":"/reference/doubsim3.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"simulated draws of top card from a shuffled  deck of cards — doubsim3","text":"character vector","code":""},{"path":"/reference/egr1_ex.html","id":null,"dir":"Reference","previous_headings":"","what":"RNASeq2GeneNorm measures for EGR1 from TCGA ACC samples — egr1_ex","title":"RNASeq2GeneNorm measures for EGR1 from TCGA ACC samples — egr1_ex","text":"RNASeq2GeneNorm measures EGR1 TCGA ACC samples","code":""},{"path":"/reference/egr1_ex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RNASeq2GeneNorm measures for EGR1 from TCGA ACC samples — egr1_ex","text":"","code":"egr1_ex"},{"path":"/reference/egr1_ex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"RNASeq2GeneNorm measures for EGR1 from TCGA ACC samples — egr1_ex","text":"numeric vector","code":""},{"path":"/reference/faces.html","id":null,"dir":"Reference","previous_headings":"","what":"get faces of a collection of cards — faces","title":"get faces of a collection of cards — faces","text":"get faces collection cards","code":""},{"path":"/reference/faces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get faces of a collection of cards — faces","text":"","code":"faces(x)"},{"path":"/reference/faces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get faces of a collection of cards — faces","text":"x card deck made `build_deck`","code":""},{"path":"/reference/faces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get faces of a collection of cards — faces","text":"","code":"d = build_deck() d[1] #> [1] \"2 ♡\" faces(d[1:2]) #> [1] \"2\" \"3\""},{"path":"/reference/fos_ex.html","id":null,"dir":"Reference","previous_headings":"","what":"RNASeq2GeneNorm measures for FOS from TCGA ACC samples — fos_ex","title":"RNASeq2GeneNorm measures for FOS from TCGA ACC samples — fos_ex","text":"RNASeq2GeneNorm measures FOS TCGA ACC samples","code":""},{"path":"/reference/fos_ex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RNASeq2GeneNorm measures for FOS from TCGA ACC samples — fos_ex","text":"","code":"fos_ex"},{"path":"/reference/fos_ex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"RNASeq2GeneNorm measures for FOS from TCGA ACC samples — fos_ex","text":"numeric vector","code":""},{"path":"/reference/full_house.html","id":null,"dir":"Reference","previous_headings":"","what":"test for full house — full_house","title":"test for full house — full_house","text":"test full house","code":""},{"path":"/reference/full_house.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"test for full house — full_house","text":"","code":"full_house(x)"},{"path":"/reference/full_house.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"test for full house — full_house","text":"x vector cards","code":""},{"path":"/reference/full_house.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"test for full house — full_house","text":"","code":"d = build_deck() h1 = c(d[1], d[14], d[27], d[2], d[15]) h1 #> [1] \"2 ♡\" \"2 ♢\" \"2 ♣\" \"3 ♡\" \"3 ♢\" full_house(h1) #> [1] TRUE h2 = c(d[1], d[14], d[27], d[2], d[16]) h2 #> [1] \"2 ♡\" \"2 ♢\" \"2 ♣\" \"3 ♡\" \"4 ♢\" full_house(h2) #> [1] FALSE"},{"path":"/reference/is_flush.html","id":null,"dir":"Reference","previous_headings":"","what":"test for flush — is_flush","title":"test for flush — is_flush","text":"test flush","code":""},{"path":"/reference/is_flush.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"test for flush — is_flush","text":"","code":"is_flush(x)"},{"path":"/reference/is_flush.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"test for flush — is_flush","text":"x vector cards","code":""},{"path":"/reference/is_flush.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"test for flush — is_flush","text":"","code":"d = build_deck() h1 = c(d[1:4], d[6]) h1 #> [1] \"2 ♡\" \"3 ♡\" \"4 ♡\" \"5 ♡\" \"7 ♡\" is_flush(h1) #> [1] TRUE"},{"path":"/reference/one_pair.html","id":null,"dir":"Reference","previous_headings":"","what":"test for one pair — one_pair","title":"test for one pair — one_pair","text":"test one pair","code":""},{"path":"/reference/one_pair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"test for one pair — one_pair","text":"","code":"one_pair(x)"},{"path":"/reference/one_pair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"test for one pair — one_pair","text":"x vector cards","code":""},{"path":"/reference/one_pair.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"test for one pair — one_pair","text":"logical(1)","code":""},{"path":"/reference/one_pair.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"test for one pair — one_pair","text":"","code":"d = build_deck() hand_1 = c(d[1], d[14], d[2:4] ) hand_1 #> [1] \"2 ♡\" \"2 ♢\" \"3 ♡\" \"4 ♡\" \"5 ♡\" one_pair(hand_1[1]) #> [1] FALSE hand_2 = c(d[1], d[6], d[2:4] ) hand_2 #> [1] \"2 ♡\" \"7 ♡\" \"3 ♡\" \"4 ♡\" \"5 ♡\" one_pair(hand_2[2]) #> [1] FALSE"},{"path":"/reference/suits.html","id":null,"dir":"Reference","previous_headings":"","what":"get suits of a collection of cards — suits","title":"get suits of a collection of cards — suits","text":"get suits collection cards","code":""},{"path":"/reference/suits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get suits of a collection of cards — suits","text":"","code":"suits(x)"},{"path":"/reference/suits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get suits of a collection of cards — suits","text":"x card deck made `build_deck`","code":""},{"path":"/reference/suits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get suits of a collection of cards — suits","text":"","code":"d = build_deck() d[1] #> [1] \"2 ♡\" suits(d[1:2]) #> [1] \"♡\" \"♡\""},{"path":"/reference/two_pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"test for two pairs — two_pairs","title":"test for two pairs — two_pairs","text":"test two pairs","code":""},{"path":"/reference/two_pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"test for two pairs — two_pairs","text":"","code":"two_pairs(x)"},{"path":"/reference/two_pairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"test for two pairs — two_pairs","text":"x vector cards","code":""},{"path":"/reference/two_pairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"test for two pairs — two_pairs","text":"","code":"d = build_deck() h1 = c(d[1], d[14], d[27], d[2], d[15]) h1 #> [1] \"2 ♡\" \"2 ♢\" \"2 ♣\" \"3 ♡\" \"3 ♢\" two_pairs(h1) #> [1] FALSE"},{"path":"/reference/yy1_ex.html","id":null,"dir":"Reference","previous_headings":"","what":"RNASeq2GeneNorm measures for YY1 from TCGA ACC samples — yy1_ex","title":"RNASeq2GeneNorm measures for YY1 from TCGA ACC samples — yy1_ex","text":"RNASeq2GeneNorm measures YY1 TCGA ACC samples","code":""},{"path":"/reference/yy1_ex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RNASeq2GeneNorm measures for YY1 from TCGA ACC samples — yy1_ex","text":"","code":"yy1_ex"},{"path":"/reference/yy1_ex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"RNASeq2GeneNorm measures for YY1 from TCGA ACC samples — yy1_ex","text":"numeric vector","code":""}]
